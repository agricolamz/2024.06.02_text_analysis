---
title: Инструменты для анализа текста в R
subtitle: летняя школа "Душа и процессор"
author: 
  - name: О. В. Алиева
  - name: Г. А. Мороз
date: today
date-format: D.MM.YYYY
format: html
editor: source
code-fold: show
lang: ru
bibliography: references.bib
toc: true
abstract: >
  Язык программирования R дает исследователю полный набор инструментов для 
  анализа текста. На занятии мы познакомимся с некоторыми из них, такими как 
  анализ частотности, векторизация и кластеризация. Кроме того, обсудим, какие 
  научные задачи могут решаться при помощи этих методов в историко-философских 
  и историко-культурных исследованиях. Опыт программирования не требуется.
---

## Введение

## Введение в R

### Установка R и RStudio

Мы будем использовать R [@r_core_team], так что для занятий понадобятся:

- R
    - [на Windows](https://cran.r-project.org/bin/windows/base/)
    - [на Mac](https://cran.r-project.org/bin/macosx/)
    - [на Linux](https://cran.rstudio.com/bin/linux/), также можно установить из командной строки:
    
```
sudo apt-get install r-cran-base
```

- RStudio --- IDE для R ([можно скачать здесь](https://www.rstudio.com/products/rstudio/download/))

Часто можно увидеть или услышать, что R --- язык программирования для "статистической обработки данных". Изначально это, конечно, было правдой, но уже давно R --- это полноценный язык программирования, который при помощи своих пакетов позволяет решать огромный спектр задач. Мы будем использовать следующую версию R:

```{r}
#| echo: false

sessionInfo()$R.version$version.string |> cat()
```

Некоторые люди не любят устанавливать лишние программы себе на компьютер, несколько вариантов есть и для них:

- [RStudio cloud](https://posit.co/download/rstudio-desktop/) --- полная функциональность RStudio с некоторыми ограничениями;
- [webR REPL](https://webr.r-wasm.org/latest/) --- ограниченная версия компилятора R, которая работает в вашем браузере и не требует никаких установок на компьютер
- [Jupyter](https://jupyter.org/) ноутбуки;
- [Google Colab](https://colab.research.google.com) (нужно в настройках переключить ядро);
- [VS Code](https://code.visualstudio.com/) --- другое IDE, которое также позволяет работать с R;
- в принципе, в IDE нет нужды, можно работать из терминала, после установки, нужно всего лишь набрать `R`.

### Знакомство с RStudio

`RStudio` --- основной IDE для R. После установки R и RStudio можно открыть RStudio и перед вами предстанет что-то похожее на изображение ниже:

![RStudio при первом открытии](images/01_01_rstudio_initial_view.png)
После нажатия на двойное окошко чуть левее надписи *Environment* откроется окно скрипта.

![Подокна RStudio](images/01_02_rstudio_initial_view.png)

Все следующие команды можно 

- вводить в окне консоли, и тогда для исполнения следует нажимать клавишу `Enter`.
- вводить в окне скрипта, и тогда для исполнения следует нажимать клавиши `Ctrl/Cmd + Enter` или на команду Run на панели окна скрипта. Все, что введено в окне скрипта можно редактировать как в любом текстовом редакторе, в том числе сохранять `Ctrl/Cmd + S`.

### R как калькулятор

Давайте начнем с самого простого и попробуем использовать R как простой калькулятор. `+`, `-`, `*`, `/`, `^` (степень), `()` и т. д.

```{r}
40+2
3-2
5*6
99/9
2+4*2
(2+4)*2
2^3
```

### Создание переменных

```{r}
x <- "гнев, богиня, воспой"

y <- sqrt(2)
```

### Пайпы

### Работа с пакетами

```{r}
library(tidyverse)
```

### Чтение текстовых файлов

В пакете `readr` (входит в `tidyverse`) для чтения текста есть функция `read_lines()`. В качестве первой переменной может выступать путь к файлу на компьютере или интернет ссылка:

```{r}
alices_adventures_in_wonderland <- read_lines("https://raw.githubusercontent.com/agricolamz/daR4hs/main/data/w5_alices_adventures_in_wonderland.txt")
head(alices_adventures_in_wonderland, 20)
```

В большинстве случаев, тексты получится считать, однако иногда при работе со старыми архивами могут возникнуть проблемы с кодировками, например, все тексты в старейшей интернет-библиотеке на русском языке --- библиотеке Максима Машкова ([lib.ru](lib.ru)) --- записаны в `KOI8-R`:

```{r}
read_lines("https://raw.githubusercontent.com/agricolamz/daR4hs/main/data/w5_the_captains_daughter_koi8r.txt",
           n_max = 15)
```

В функциях пакета `readr` (т. е. не только `read_lines()`, но и в функциях `read_csv()`, `read_tsv()` и т. п.) есть аргумент `locale`, который позволяет эксплицитно указать кодировку, а при считывании происходит процесс конвертации в стандартный для многих операционных систем `UTF-8`. Для текстов на русском языке важны следующие кодировки

- `KOI8-R`, а для украинского языка --- `KOI8-U`;
- `CP1251` (также известная под названием `Windows-1251`) покрывает и другие кириллические письменности такие как украинский, белорусский, болгарский, сербский, македонский и другие.

```{r}
read_lines("https://raw.githubusercontent.com/agricolamz/daR4hs/main/data/w5_the_captains_daughter_koi8r.txt",
           locale = locale(encoding = "KOI8-R"), 
           n_max = 15)

read_lines("https://raw.githubusercontent.com/agricolamz/daR4hs/main/data/w5_the_captains_daughter_cp1251.txt",
           locale = locale(encoding = "CP1251"),
           n_max = 15)
```

Для просмотра и изменения кодировки внутри R следует использовать функцию `Encoding()`:

```{r}
x <- "fa\xE7ile"
x
Encoding(x)
```

Теперь можем использовать функцию присваивания:

```{r}
Encoding(x) <- "latin1"
x
Encoding(x)
```

Если необходимо преобразовать из одной кодировки в другую, следует использовать функцию `iconv()`:

```{r}
x <- iconv(x, "latin1", "UTF-8")
Encoding(x)
x
```

## Работа с корпусом текстов

### `tidy`-формат

### Считываем наш корпус

Чтобы прочитать корпус текстов, укажите путь к ним из рабочей директории. Узнать, какая директория у вас рабочая, можно так:

```{r eval=FALSE}
getwd()
```

Изменить рабочую директорию можно из панели инструментов (вкладка `Session`, `Set Working Directory`) или при помощи функции `setwd()`, указав в качестве аргумента путь к рабочей директории на вашем компьютере (в кавычках, так как это символьный вектор). 

Загрузите в вашу рабочую директорию файлы с корпусом текстов Платона. Их можно найти по [ссылке](https://github.com/agricolamz/2024.06.02_text_analysis/blob/main/data.zip).  

![](images/download_zip.png)

Папка `data` содержит две вложенные: `plato_w` c переводами Платона и `plato_l` с лемматизированными текстами. Нам понадобятся обе, поместите `data` со всем содержимым в рабочую директорию. 

Узнаем, какие файлы лежат в папке `plato_l`:

```{r}
filenames <- list.files("./data/plato_l") 
head(filenames) 
length(filenames)
```
Объект `filenames` -- это символьный вектор, в котором 51 элемент. В нем хранятся названия файлов с диалогами. Функция `head()` выводит только первые шесть названий.

Теперь наша задача -- прочитать их все в R, чтобы можно было посчитать частотности. Для этого сначала превратим имена в пути.

```{r}
filepaths <- file.path("data", "plato_l", filenames)
head(filepaths)
```
Теперь нам нужен цикл, который продется по всем файлам и соберет оттуда текст. 

```{r}
corpus <- map(filepaths, read_lines)
```

Теперь у вас в окружении появился список `corpus`, в котором 51 элемент, по числу файлов. Достать любой элемент из списка и посмотреть на него можно по индексу. Текст большой, поэтому снова выведем только начало.

```{r}
head(corpus[[1]], 29)
```

Каждому элементу списка можно присвоить имя:

```{r}
cnames <- str_remove(filenames, "\\.txt")

names(corpus) <- cnames
```

Нажмите на объект в окружении, чтобы понять, что изменилось.

## Анализ частотности n-gram

В нашем корпусе текст уже разделен на отдельные слова (и знаки препинания), потому что предварительно мы его _лемматизировали_. Это значит, что все слова были автоматически приведены к начальной форме (лемме). 

Прежде чем их считать, удобно превратить объект `corpus` из списка в таблицу (tibble), чтобы можно было работать с использованием `tidyverse`.

```{r}
corpus_tbl <- corpus %>% 
  stack() %>% 
  as_tibble() %>% 
  transmute(text = ind, word = values)

head(corpus_tbl)
nrow(corpus_tbl)
```

У нас получилась очень длинная таблица, в которой хранятся все слова для диалогов. Узнаем, сколько слов в каждом тексте:

```{r}
total <- corpus_tbl %>% 
  group_by(text) %>% 
  summarise(total = n()) %>% 
  arrange(-total)

DT::datatable(total)
```

Нам осталось посчитать частотность для каждого слова и разделить на общее число слов. Таким образом мы узнаем относительную частотность (tf) для каждого слова, и сможем отобрать наиболее частотные или, наоборот, редкие слова. Перед этим имеет смысл перевести все слова в нижний регистр. Обратите внимание, что таблица `corpus_counts` уже не такая длинная, как `corpus_tbl`.

```{r}
corpus_counts <- corpus_tbl %>% 
  count(text, word) %>% 
  arrange(-n)

head(corpus_counts)
nrow(corpus_counts)
```

Ожидаемо среди самых частотных единиц оказались знаки препинания, но нам они не интересны. Поэтому просто избавимся от всех рядов с пунктуацией.

```{r}
corpus_counts <- corpus_counts %>% 
  filter(!str_detect(word, "[[:punct:]<>]")) %>% 
  arrange(-n)

head(corpus_counts)
```

## Стопслова

## Пакет `stopwords`

Выше мы упомянули, что в пакет `tidytext` встроен список английских стопслов. Стопслова для других язков можно раздобыть списки для других языков, используя пакет `stopwords`. Вместо имени языка, функция принимает ISO код языыка:

```{r}
library(stopwords)
stopwords("ru")
```

Пакет предоставляет несколько источников списков:

```{r}
stopwords_getsources()
```

Давайте посмотрим какие языки сейчас доступны:

```{r}
map(stopwords_getsources(), stopwords_getlanguages)
```

Мы видим, что есть несколько источников для русского языка:

```{r}
length(stopwords("ru", source = "snowball"))
length(stopwords("ru", source = "stopwords-iso"))
length(stopwords("ru", source = "marimo"))
length(stopwords("ru", source = "nltk"))
```

## Мера tf-idf

## Анализ коллокаций

## Кластеризация авторов на основе частотности языковых единиц

## Векторизация
